server:
  port: 9013
spring:
  ##################################################################################################
  #                               nacos
  #                           192.168.60.119:8848
  #                           192.168.188.106:8848
  ##################################################################################################
  application:
    name: kafkaCounsunmer
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.188.106:8848
        namespace: cc8561c5-2d87-4db8-95fc-ddc0fb03e563
      config:
        server-addr: ${spring.cloud.nacos.discovery.server-addr}
        namespace: ${spring.cloud.nacos.discovery.namespace}
        file-extension: yaml
        prefix: ${spring.application.name}
  profiles:
    active: dev
  kafka:
#    bootstrap-servers: 192.168.60.119:9092
    bootstrap-servers: 192.168.188.126:9092
    producer:
      # 每次批量发送消息的数量
      batch-size: 16
      # 缓存容量
      buffer-memory: 33554432
      #设置大于0的值，则客户端会将发送失败的记录重新发送
      retries: 0
      # 指定消息key和消息体的编解码方式 UTF-8
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    listener:
      type: batch
      #      并发连接池
      concurrency: 5
      #消费监听接口监听的主题不存在时，默认会报错
      missing-topics-fatal: false
    consumer:
      max-poll-records: 100
kafka:
  #订阅的主题
  topic: socket
  #主题消费分组
  group: group-test-01
